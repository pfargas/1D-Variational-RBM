{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter\n",
    "using Random #, Distributions\n",
    "using PyPlot\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct PTParams{T}\n",
    "    TMax       :: T\n",
    "    λ          :: T\n",
    "    NTemps     :: Int\n",
    "    Nexchanges :: Int\n",
    "    PTParams{T}() where {T} = new()\n",
    "end;\n",
    "\n",
    "mutable struct MetropolisParams{T}\n",
    "    NSteps       :: Int\n",
    "    StepSize     :: T\n",
    "    GaussianStep :: Bool\n",
    "    MetropolisParams{T}() where {T} = new()\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data structure for the points of the phase space\n",
    "\n",
    "x is a tensor with NTemp walkers, each one with d dimensions. The structure will be:\n",
    "\n",
    "$x[temp, dim]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "energy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function energy(x::Vector{T}, λ, b, W, c) where {T}\n",
    "    # Example energy function: sum of squares\n",
    "    return sum(x .^ 2) # TODO: replace with actual energy function of the physical system\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "energy_CUDA (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function energy_CUDA(x, λ, b, W, c, energies)\n",
    "    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    Nchains = size(x, 1)\n",
    "    D = size(x, 2)\n",
    "    if i <= Nchains\n",
    "        energies[i] = energy(x[i, :], λ, b, W, c)\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mock_energy_CUDA (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function gauss_2d(x ,μ, σ)\n",
    "    return exp(-0.5 * ((x[1] - μ[1])^2 + (x[2] - μ[2])^2) / σ^2)\n",
    "end\n",
    "\n",
    "@inline function gauss_nd(x::NTuple{D, T}, μ::NTuple{D, T}, σ::T) where {D, T}\n",
    "    s = zero(T)\n",
    "    @inbounds for i in 1:D\n",
    "        s += (x[i] - μ[i])^2\n",
    "    end\n",
    "    return exp(-0.5 * s / σ^2)\n",
    "end\n",
    "\n",
    "\n",
    "@inline function ener_landscape(x::NTuple{D, T}) where {D, T}\n",
    "    μ1 = ntuple(i -> zero(T), D)\n",
    "    μ2 = ntuple(i -> T(5.0), D)\n",
    "    return gauss_nd(x, μ1, 1.0) + 0.5 * gauss_nd(x, μ2, 1.0)\n",
    "end\n",
    "\n",
    "# function ener_landscape(x_actual)\n",
    "#     return gauss_2d(x_actual, [0.0, 0.0], 1.0) + 0.5*gauss_2d(x_actual, [5.0, 5.0], 1.0)\n",
    "# end\n",
    "\n",
    "function mock_energy_CUDA(x, energies)\n",
    "    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    Nchains = size(x, 1)\n",
    "    D = size(x, 2)\n",
    "    if i <= Nchains\n",
    "        x_actual = ntuple(j -> x[i, j], Val(D))\n",
    "        # Mock energy function for testing\n",
    "        # gaussian landscape in 2D\n",
    "        energies[i] = ener_landscape(x_actual)\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(-10, stop=10, length=100)\n",
    "y = range(-10, stop=10, length=100)\n",
    "# generate a matrix of x and y values, without meshgrid\n",
    "X = zeros(length(x), length(y))\n",
    "Y = zeros(length(x), length(y))\n",
    "for i in 1:length(x)\n",
    "    for j in 1:length(y)\n",
    "        X[i, j] = x[i]\n",
    "        Y[i, j] = y[j]\n",
    "    end\n",
    "end\n",
    "\n",
    "Z = zeros(size(X))\n",
    "for i in 1:size(X, 1)\n",
    "    for j in 1:size(X, 2)\n",
    "        Z[i, j] = ener_landscape([X[i, j], Y[i, j]])\n",
    "    end\n",
    "end\n",
    "fig = figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.contourf(X, Y, Z, levels=50)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Energy Landscape\")\n",
    "savefig(\"energy_landscape.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "function parallel_tempering(PTParameters::PTParams, MetropolisParams::MetropolisParams, initial_guess)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Local variables\n",
    "    # -------------------------------------------------------\n",
    "    \n",
    "    NTemps           = PTParameters.NTemps\n",
    "    Nexchanges       = PTParameters.Nexchanges\n",
    "    TMax             = PTParameters.TMax\n",
    "    NSteps           = MetropolisParams.NSteps\n",
    "    StepSize         = MetropolisParams.StepSize\n",
    "\n",
    "    λ                = PTParameters.λ\n",
    "    temperatures     = zeros(NTemps)\n",
    "    temperatures[1]  = TMax\n",
    "    [temperatures[i] = temperatures[i-1]*λ for i in 2:NTemps]\n",
    "\n",
    "    xo               = initial_guess\n",
    "    xn               = zeros(size(xo))\n",
    "    D                = size(xo, 2)\n",
    "\n",
    "    Eveco           = zeros(NTemps) # preallocate energy vector\n",
    "    @cuda mock_energy_CUDA(xo, Eveco) # compute parallel energy\n",
    "    TupEBest        = findmin(Eveco)\n",
    "    EBest           = TupEBest[1]\n",
    "    EBestPos        = xo[TupEBest[2]]\n",
    "\n",
    "    display(\"Initial guess: \", xo)\n",
    "    display(\"Initial energies: \", Eveco)\n",
    "    display(\"Initial best energy: \", EBest[1])\n",
    "    display(\"Temperatures: \", temperatures')\n",
    "    # debug energy and init guess\n",
    "    is_plot = false\n",
    "    if is_plot\n",
    "        clf()\n",
    "        plot(-10:10, Ener.(-10:10), label=\"Energy\")\n",
    "        plot(xo, Ener.(xo), \"ro\", label=\"Initial guess\")\n",
    "        plot(EBestPos, EBest[1], \"go\", label=\"Best guess\")\n",
    "        title(\"Initial guess\")\n",
    "        xlabel(\"x\")\n",
    "        ylabel(\"Energy\")\n",
    "        legend()\n",
    "        # if ./out exists, save the figure there\n",
    "        if isdir(\"./out\")\n",
    "            savefig(\"./out/energy\")\n",
    "        else\n",
    "            show()\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Parallel tempering loop\n",
    "    # -------------------------------------------------------\n",
    "    @showprogress for _ in 1:PTParameters.Nexchanges+1\n",
    "        # Metropolis step\n",
    "        for i in 1:NSteps\n",
    "            xn = xo .+ StepSize*randn(NTemps, D) # generate new positions\n",
    "            Evecn = zeros(NTemps) # preallocate energy vector\n",
    "            @cuda mock_energy_CUDA(xn, Evecn) # compute parallel energy\n",
    "            ΔE_vec = Evecn .- Eveco # compute the energy difference between the new and old positions\n",
    "\n",
    "            mask1 = ΔE_vec .< 0 # if the new position is better, accept it\n",
    "            mask2 = !mask1 & (rand(NTemps) .< exp.(-ΔE_vec./temperatures)) # if the new position is worse, metropolis probability\n",
    "            mask = mask1 .| mask2 # combine the two masks\n",
    "            for i in 1:D\n",
    "                xo[i] = xn[i] .* mask .+ xo[i] .* .!mask\n",
    "            end\n",
    "\n",
    "            Eveco = zeros(NTemps) # preallocate energy vector\n",
    "            @cuda mock_energy_CUDA(xo, Eveco) # compute parallel energy\n",
    "            prob_best_guess = findmin(Eveco) # from the new sampled energies, find the best guess\n",
    "            if prob_best_guess[1] < EBest # compare the new best guess with the old one. If its better, update it\n",
    "                # EBest: energy, position\n",
    "                # EBestPos: position\n",
    "                EBest    = prob_best_guess[1]\n",
    "                EBestPos = xo[prob_best_guess[2]]\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # Exchange step\n",
    "        # no check for the lowest state, as we don't explore space here\n",
    "        exchange_energies = zeros(NTemps)\n",
    "        @cuda mock_energy_CUDA(xo, exchange_energies) # compute parallel energy\n",
    "        for temp in 1:NTemps-1\n",
    "            ΔE_exchange_no_T = exchange_energies[temp] - exchange_energies[temp+1]\n",
    "            ΔE_exchange = ΔE_exchange_no_T * (1/temperatures[temp] - 1/temperatures[temp+1])\n",
    "            if ΔE_exchange < 0\n",
    "                xo[temp, :], xo[temp+1, :] = xo[temp+1, :], xo[temp, :]\n",
    "            elseif rand() < exp(-ΔE_exchange)\n",
    "                xo[temp, :], xo[temp+1, :] = xo[temp+1, :], xo[temp, :]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return xo, EBest, EBestPos\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "GPUCompiler.InvalidIRError",
     "evalue": "InvalidIRError: compiling MethodInstance for mock_energy_CUDA(::CuDeviceMatrix{Float64, 1}, ::CuDeviceVector{Float64, 1}) resulted in invalid LLVM IR\nReason: unsupported call to an unknown function (call to jl_f_apply_type)\nStacktrace:\n [1] Val\n   @ ./essentials.jl:1037\n [2] mock_energy_CUDA\n   @ ~/Desktop/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:29\nReason: unsupported call to an unknown function (call to ijl_new_structv)\nStacktrace:\n [1] Val\n   @ ./essentials.jl:1035\n [2] Val\n   @ ./essentials.jl:1037\n [3] mock_energy_CUDA\n   @ ~/Desktop/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:29\nReason: unsupported dynamic function invocation (call to ntuple)\nStacktrace:\n [1] mock_energy_CUDA\n   @ ~/Desktop/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:29\nReason: unsupported dynamic function invocation (call to ener_landscape)\nStacktrace:\n [1] mock_energy_CUDA\n   @ ~/Desktop/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:32\nReason: unsupported dynamic function invocation (call to convert)\nStacktrace:\n [1] setindex!\n   @ ~/.julia/packages/CUDA/RQqFT/src/device/array.jl:177\n [2] mock_energy_CUDA\n   @ ~/Desktop/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:32\nHint: catch this exception as `err` and call `code_typed(err; interactive = true)` to introspect the erronous code with Cthulhu.jl",
     "output_type": "error",
     "traceback": [
      "InvalidIRError: compiling MethodInstance for mock_energy_CUDA(::CuDeviceMatrix{Float64, 1}, ::CuDeviceVector{Float64, 1}) resulted in invalid LLVM IR\n",
      "Reason: unsupported call to an unknown function (call to jl_f_apply_type)\n",
      "Stacktrace:\n",
      " [1] Val\n",
      "   @ ./essentials.jl:1037\n",
      " [2] mock_energy_CUDA\n",
      "   @ ~/Desktop/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:29\n",
      "Reason: unsupported call to an unknown function (call to ijl_new_structv)\n",
      "Stacktrace:\n",
      " [1] Val\n",
      "   @ ./essentials.jl:1035\n",
      " [2] Val\n",
      "   @ ./essentials.jl:1037\n",
      " [3] mock_energy_CUDA\n",
      "   @ ~/Desktop/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:29\n",
      "Reason: unsupported dynamic function invocation (call to ntuple)\n",
      "Stacktrace:\n",
      " [1] mock_energy_CUDA\n",
      "   @ ~/Desktop/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:29\n",
      "Reason: unsupported dynamic function invocation (call to ener_landscape)\n",
      "Stacktrace:\n",
      " [1] mock_energy_CUDA\n",
      "   @ ~/Desktop/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:32\n",
      "Reason: unsupported dynamic function invocation (call to convert)\n",
      "Stacktrace:\n",
      " [1] setindex!\n",
      "   @ ~/.julia/packages/CUDA/RQqFT/src/device/array.jl:177\n",
      " [2] mock_energy_CUDA\n",
      "   @ ~/Desktop/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:32\n",
      "Hint: catch this exception as `err` and call `code_typed(err; interactive = true)` to introspect the erronous code with Cthulhu.jl\n",
      "\n",
      "Stacktrace:\n",
      "  [1] check_ir(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, args::LLVM.Module)\n",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/OGnEB/src/validation.jl:167\n",
      "  [2] macro expansion\n",
      "    @ ~/.julia/packages/GPUCompiler/OGnEB/src/driver.jl:381 [inlined]\n",
      "  [3] emit_llvm(job::GPUCompiler.CompilerJob; toplevel::Bool, libraries::Bool, optimize::Bool, cleanup::Bool, validate::Bool, only_entry::Bool)\n",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/OGnEB/src/utils.jl:110\n",
      "  [4] emit_llvm\n",
      "    @ ~/.julia/packages/GPUCompiler/OGnEB/src/utils.jl:108 [inlined]\n",
      "  [5] codegen(output::Symbol, job::GPUCompiler.CompilerJob; toplevel::Bool, libraries::Bool, optimize::Bool, cleanup::Bool, validate::Bool, strip::Bool, only_entry::Bool, parent_job::Nothing)\n",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/OGnEB/src/driver.jl:100\n",
      "  [6] codegen\n",
      "    @ ~/.julia/packages/GPUCompiler/OGnEB/src/driver.jl:82 [inlined]\n",
      "  [7] compile(target::Symbol, job::GPUCompiler.CompilerJob; kwargs::@Kwargs{})\n",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/OGnEB/src/driver.jl:79\n",
      "  [8] compile\n",
      "    @ ~/.julia/packages/GPUCompiler/OGnEB/src/driver.jl:74 [inlined]\n",
      "  [9] #1171\n",
      "    @ ~/.julia/packages/CUDA/RQqFT/src/compiler/compilation.jl:255 [inlined]\n",
      " [10] JuliaContext(f::CUDA.var\"#1171#1174\"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}}; kwargs::@Kwargs{})\n",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/OGnEB/src/driver.jl:34\n",
      " [11] JuliaContext(f::Function)\n",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/OGnEB/src/driver.jl:25\n",
      " [12] compile(job::GPUCompiler.CompilerJob)\n",
      "    @ CUDA ~/.julia/packages/CUDA/RQqFT/src/compiler/compilation.jl:254\n",
      " [13] actual_compilation(cache::Dict{Any, CuFunction}, src::Core.MethodInstance, world::UInt64, cfg::GPUCompiler.CompilerConfig{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, compiler::typeof(CUDA.compile), linker::typeof(CUDA.link))\n",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/OGnEB/src/execution.jl:237\n",
      " [14] cached_compilation(cache::Dict{Any, CuFunction}, src::Core.MethodInstance, cfg::GPUCompiler.CompilerConfig{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, compiler::Function, linker::Function)\n",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/OGnEB/src/execution.jl:151\n",
      " [15] macro expansion\n",
      "    @ ~/.julia/packages/CUDA/RQqFT/src/compiler/execution.jl:373 [inlined]\n",
      " [16] macro expansion\n",
      "    @ ./lock.jl:273 [inlined]\n",
      " [17] cufunction(f::typeof(mock_energy_CUDA), tt::Type{Tuple{CuDeviceMatrix{Float64, 1}, CuDeviceVector{Float64, 1}}}; kwargs::@Kwargs{})\n",
      "    @ CUDA ~/.julia/packages/CUDA/RQqFT/src/compiler/execution.jl:368\n",
      " [18] cufunction(f::typeof(mock_energy_CUDA), tt::Type{Tuple{CuDeviceMatrix{Float64, 1}, CuDeviceVector{Float64, 1}}})\n",
      "    @ CUDA ~/.julia/packages/CUDA/RQqFT/src/compiler/execution.jl:365\n",
      " [19] top-level scope\n",
      "    @ ~/.julia/packages/CUDA/RQqFT/src/compiler/execution.jl:112"
     ]
    }
   ],
   "source": [
    "NTemps = 10\n",
    "test = zeros(NTemps)\n",
    "x_tests = randn(NTemps, 2) # random initial guess\n",
    "test = CuArray(test)\n",
    "x_tests = CuArray(x_tests)\n",
    "@cuda mock_energy_CUDA(x_tests, test)\n",
    "# check if the energies are computed correctly\n",
    "for energy in test\n",
    "    println(energy)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

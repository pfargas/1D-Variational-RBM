{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter\n",
    "using Random #, Distributions\n",
    "using PyPlot\n",
    "using CUDA\n",
    "using StaticArrays\n",
    "D = 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct PTParams{T}\n",
    "    TMax       :: T\n",
    "    λ          :: T\n",
    "    NTemps     :: Int\n",
    "    Nexchanges :: Int\n",
    "    PTParams{T}() where {T} = new()\n",
    "end;\n",
    "\n",
    "mutable struct MetropolisParams{T}\n",
    "    NSteps       :: Int\n",
    "    StepSize     :: T\n",
    "    GaussianStep :: Bool\n",
    "    MetropolisParams{T}() where {T} = new()\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data structure for the points of the phase space\n",
    "\n",
    "x is a tensor with NTemp walkers, each one with d dimensions. The structure will be:\n",
    "\n",
    "$x[temp, dim]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "energy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function energy(x::Vector{T}, λ, b, W, c) where {T}\n",
    "    # Example energy function: sum of squares\n",
    "    return sum(x .^ 2) # TODO: replace with actual energy function of the physical system\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "energy_CUDA (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function energy_CUDA(x, λ, b, W, c, energies)\n",
    "    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    Nchains = size(x, 1)\n",
    "    D = size(x, 2)\n",
    "    if i <= Nchains\n",
    "        energies[i] = energy(x[i, :], λ, b, W, c)\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mock_energy_CUDA (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function gauss_2d(x ,μ, σ)\n",
    "    return exp(-0.5 * ((x[1] - μ[1])^2 + (x[2] - μ[2])^2) / σ^2)\n",
    "end\n",
    "\n",
    "@inline function gauss_nd(x::NTuple{D, T}, μ::NTuple{D, T}, σ::T) where {D, T}\n",
    "    s = zero(T)\n",
    "    @inbounds for i in 1:D\n",
    "        s += (x[i] - μ[i])^2\n",
    "    end\n",
    "    return exp(-0.5 * s / σ^2)\n",
    "end\n",
    "\n",
    "\n",
    "@inline function ener_landscape(x::NTuple{D, T}) where {D, T}\n",
    "    # μ1 = @SVector zeros(T, D)\n",
    "    # μ2 = @SVector fill(T(5.0), D)\n",
    "    return gauss_nd(x, 0.0, 1.0) + 0.5 * gauss_nd(x, 5.0, 1.0)\n",
    "end\n",
    "\n",
    "function mock_energy_CUDA(x, energies)\n",
    "    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    Nchains = size(x, 1)\n",
    "    if i <= Nchains\n",
    "\n",
    "        # Inlining the Gaussian landscape calculation directly into the kernel\n",
    "        μ1 = zero(Float64)  # μ1 = (0,0) (zero vector)\n",
    "        μ2 = 5.0  # μ2 = (5,5) (scalar for simplicity)\n",
    "        \n",
    "        s1 = zero(Float64)\n",
    "        s2 = zero(Float64)\n",
    "        \n",
    "        # Compute squared differences directly in the kernel\n",
    "        @inbounds for j in 1:D\n",
    "            s1 += (x[i,j] - μ1)^2\n",
    "            s2 += (x[i,j] - μ2)^2\n",
    "        end\n",
    "        \n",
    "        energy = exp(-0.5 * s1) + 0.5 * exp(-0.5 * s2)  # Combine the Gaussian terms\n",
    "        \n",
    "        energies[i] = energy\n",
    "\n",
    "\n",
    "\n",
    "        # energies[i] = ener_landscape(x_actual)\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching ener_landscape(::Vector{Float64})\nThe function `ener_landscape` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  ener_landscape(!Matched::NTuple{D, T}) where {D, T}\n   @ Main ~/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W5sZmlsZQ==.jl:14\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching ener_landscape(::Vector{Float64})\n",
      "The function `ener_landscape` exists, but no method is defined for this combination of argument types.\n",
      "\n",
      "Closest candidates are:\n",
      "  ener_landscape(!Matched::NTuple{D, T}) where {D, T}\n",
      "   @ Main ~/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W5sZmlsZQ==.jl:14\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:16"
     ]
    }
   ],
   "source": [
    "x = range(-10, stop=10, length=100)\n",
    "y = range(-10, stop=10, length=100)\n",
    "# generate a matrix of x and y values, without meshgrid\n",
    "X = zeros(length(x), length(y))\n",
    "Y = zeros(length(x), length(y))\n",
    "for i in 1:length(x)\n",
    "    for j in 1:length(y)\n",
    "        X[i, j] = x[i]\n",
    "        Y[i, j] = y[j]\n",
    "    end\n",
    "end\n",
    "\n",
    "Z = zeros(size(X))\n",
    "for i in 1:size(X, 1)\n",
    "    for j in 1:size(X, 2)\n",
    "        Z[i, j] = ener_landscape([X[i, j], Y[i, j]])\n",
    "    end\n",
    "end\n",
    "fig = figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.contourf(X, Y, Z, levels=50)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Energy Landscape\")\n",
    "savefig(\"energy_landscape.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "function parallel_tempering(PTParameters::PTParams, MetropolisParams::MetropolisParams, initial_guess)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Local variables\n",
    "    # -------------------------------------------------------\n",
    "    \n",
    "    NTemps           = PTParameters.NTemps\n",
    "    Nexchanges       = PTParameters.Nexchanges\n",
    "    TMax             = PTParameters.TMax\n",
    "    NSteps           = MetropolisParams.NSteps\n",
    "    StepSize         = MetropolisParams.StepSize\n",
    "\n",
    "    λ                = PTParameters.λ\n",
    "    temperatures     = zeros(NTemps)\n",
    "    temperatures[1]  = TMax\n",
    "    [temperatures[i] = temperatures[i-1]*λ for i in 2:NTemps]\n",
    "\n",
    "    xo               = initial_guess\n",
    "    xn               = zeros(size(xo))\n",
    "    D                = size(xo, 2)\n",
    "\n",
    "    Eveco           = zeros(NTemps) # preallocate energy vector\n",
    "    @cuda mock_energy_CUDA(xo, Eveco) # compute parallel energy\n",
    "    TupEBest        = findmin(Eveco)\n",
    "    EBest           = TupEBest[1]\n",
    "    EBestPos        = xo[TupEBest[2]]\n",
    "\n",
    "    display(\"Initial guess: \", xo)\n",
    "    display(\"Initial energies: \", Eveco)\n",
    "    display(\"Initial best energy: \", EBest[1])\n",
    "    display(\"Temperatures: \", temperatures')\n",
    "    # debug energy and init guess\n",
    "    is_plot = false\n",
    "    if is_plot\n",
    "        clf()\n",
    "        plot(-10:10, Ener.(-10:10), label=\"Energy\")\n",
    "        plot(xo, Ener.(xo), \"ro\", label=\"Initial guess\")\n",
    "        plot(EBestPos, EBest[1], \"go\", label=\"Best guess\")\n",
    "        title(\"Initial guess\")\n",
    "        xlabel(\"x\")\n",
    "        ylabel(\"Energy\")\n",
    "        legend()\n",
    "        # if ./out exists, save the figure there\n",
    "        if isdir(\"./out\")\n",
    "            savefig(\"./out/energy\")\n",
    "        else\n",
    "            show()\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Parallel tempering loop\n",
    "    # -------------------------------------------------------\n",
    "    @showprogress for _ in 1:PTParameters.Nexchanges+1\n",
    "        # Metropolis step\n",
    "        for i in 1:NSteps\n",
    "            xn = xo .+ StepSize*randn(NTemps, D) # generate new positions\n",
    "            Evecn = zeros(NTemps) # preallocate energy vector\n",
    "            @cuda threads=256 blocks=256 mock_energy_CUDA(xn, Evecn) # compute parallel energy\n",
    "            ΔE_vec = Evecn .- Eveco # compute the energy difference between the new and old positions\n",
    "\n",
    "            mask1 = ΔE_vec .< 0 # if the new position is better, accept it\n",
    "            mask2 = !mask1 & (rand(NTemps) .< exp.(-ΔE_vec./temperatures)) # if the new position is worse, metropolis probability\n",
    "            mask = mask1 .| mask2 # combine the two masks\n",
    "            for i in 1:D\n",
    "                xo[i] = xn[i] .* mask .+ xo[i] .* .!mask\n",
    "            end\n",
    "\n",
    "            Eveco = zeros(NTemps) # preallocate energy vector\n",
    "            @cuda threads=256 blocks=256 mock_energy_CUDA(xo, Eveco) # compute parallel energy\n",
    "            prob_best_guess = findmin(Eveco) # from the new sampled energies, find the best guess\n",
    "            if prob_best_guess[1] < EBest # compare the new best guess with the old one. If its better, update it\n",
    "                # EBest: energy, position\n",
    "                # EBestPos: position\n",
    "                EBest    = prob_best_guess[1]\n",
    "                EBestPos = xo[prob_best_guess[2]]\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # Exchange step\n",
    "        # no check for the lowest state, as we don't explore space here\n",
    "        exchange_energies = zeros(NTemps)\n",
    "        @cuda threads=256 blocks=256 mock_energy_CUDA(xo, exchange_energies) # compute parallel energy\n",
    "        for temp in 1:NTemps-1\n",
    "            ΔE_exchange_no_T = exchange_energies[temp] - exchange_energies[temp+1]\n",
    "            ΔE_exchange = ΔE_exchange_no_T * (1/temperatures[temp] - 1/temperatures[temp+1])\n",
    "            if ΔE_exchange < 0\n",
    "                xo[temp, :], xo[temp+1, :] = xo[temp+1, :], xo[temp, :]\n",
    "            elseif rand() < exp(-ΔE_exchange)\n",
    "                xo[temp, :], xo[temp+1, :] = xo[temp+1, :], xo[temp, :]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return xo, EBest, EBestPos\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "Scalar indexing is disallowed.\nInvocation of getindex resulted in scalar indexing of a GPU array.\nThis is typically caused by calling an iterating implementation of a method.\nSuch implementations *do not* execute on the GPU, but very slowly on the CPU,\nand therefore should be avoided.\n\nIf you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\nto enable scalar iteration globally or for the operations in question.",
     "output_type": "error",
     "traceback": [
      "Scalar indexing is disallowed.\n",
      "Invocation of getindex resulted in scalar indexing of a GPU array.\n",
      "This is typically caused by calling an iterating implementation of a method.\n",
      "Such implementations *do not* execute on the GPU, but very slowly on the CPU,\n",
      "and therefore should be avoided.\n",
      "\n",
      "If you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\n",
      "to enable scalar iteration globally or for the operations in question.\n",
      "\n",
      "Stacktrace:\n",
      " [1] error(s::String)\n",
      "   @ Base ./error.jl:35\n",
      " [2] errorscalar(op::String)\n",
      "   @ GPUArraysCore ~/.julia/packages/GPUArraysCore/aNaXo/src/GPUArraysCore.jl:151\n",
      " [3] _assertscalar(op::String, behavior::GPUArraysCore.ScalarIndexing)\n",
      "   @ GPUArraysCore ~/.julia/packages/GPUArraysCore/aNaXo/src/GPUArraysCore.jl:124\n",
      " [4] assertscalar(op::String)\n",
      "   @ GPUArraysCore ~/.julia/packages/GPUArraysCore/aNaXo/src/GPUArraysCore.jl:112\n",
      " [5] getindex\n",
      "   @ ~/.julia/packages/GPUArrays/uiVyU/src/host/indexing.jl:50 [inlined]\n",
      " [6] iterate\n",
      "   @ ./abstractarray.jl:1209 [inlined]\n",
      " [7] iterate(A::CuArray{Float64, 1, CUDA.DeviceMemory})\n",
      "   @ Base ./abstractarray.jl:1207\n",
      " [8] top-level scope\n",
      "   @ ~/PhD/1D-Variational-RBM/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X11sZmlsZQ==.jl:8"
     ]
    }
   ],
   "source": [
    "NTemps = 10\n",
    "test = zeros(NTemps)\n",
    "x_tests = randn(NTemps, 2) # random initial guess\n",
    "test = CuArray(test)\n",
    "x_tests = CuArray(x_tests)\n",
    "@cuda threads=256 blocks=256 mock_energy_CUDA(x_tests, test)\n",
    "# check if the energies are computed correctly\n",
    "for energy in test\n",
    "    println(energy)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
